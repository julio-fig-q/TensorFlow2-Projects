{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1UsYB--LP3BnY0mVMJy3boNsIIYtnBpnn","authorship_tag":"ABX9TyN6Bij1l1NXEP1UMlzkCmX+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# The compile method is a method (function) of the model object. And it basically allow us to set functionalities of our built model, in order to train it.\n","\n","At this point this should be on the GitHub Repository btw.\n"],"metadata":{"id":"K3aprHFkLky5"}},{"cell_type":"markdown","source":["## **Binary classificaiton network**"],"metadata":{"id":"vZy3oN7ZL2eq"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense"],"metadata":{"id":"VPxnpBWjMjdR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential([\n","    Dense(64, activation='elu', input_shape=(32,)),   # Takes a 1d tensor of size 32, exponential linear activation and 64 units\n","    Dense(1, activation='sigmoid')                    # 1 neuron with sigmoid activation\n","])"],"metadata":{"id":"iMl_LSnYMscZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## We now define the optimizer and loss-function for the network"],"metadata":{"id":"QUfHDr_-NI1S"}},{"cell_type":"code","source":["model.compile(\n","    optimizer='sgd',\n","    loss='binary_crossentropy'\n",")"],"metadata":{"id":"9Lu9K_BrNPmr"},"execution_count":null,"outputs":[]}]}